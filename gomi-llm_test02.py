from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import json

# 1. JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
with open("text.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# 2. Embeddingãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨å¤‰æ›
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = model.encode(data["docs"])  # â†’ (3, 384)ã®ãƒ™ã‚¯ãƒˆãƒ«

# 3. FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆã¨ä¿å­˜
dimension = embeddings.shape[1]  # ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°ï¼ˆ384ï¼‰
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

# 4. æ¤œç´¢ç”¨ã®ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›
query = "ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯ã‚´ãƒŸã®å‡ºã—æ–¹ã¯ï¼Ÿ"
query_vec = model.encode([query])

# 5. FAISSã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆæœ€ã‚‚è¿‘ã„1ä»¶ã‚’å–å¾—ï¼‰
distances, indices = index.search(query_vec, k=1)  # k=1ã¯ä¸Šä½1ä»¶

# 6. çµæœã‚’è¡¨ç¤º
print("ğŸ” ã‚¯ã‚¨ãƒª:", query)
print("ğŸ§  ä¸€ç•ªè¿‘ã„æ–‡:", data["docs"][indices[0][0]])
print("ğŸ“ è·é›¢ã‚¹ã‚³ã‚¢:", distances[0][0])